Interview Questions - 1

Q: What is Amazon Redshift?
Amazon Redshift is a fully managed, cloud data warehouse which can help analyze petabytes of data in an easy, scalable and cost-effective manner.
Additionally, it also enable to analyze the data sitting across other storage platforms including operational databases, data lake, data warehouse, and third party data sets.

Q: What do we mean by “AWS Redshift is fully managed” ?
Redshift is fully managed by AWS, so you no longer need to worry about data warehouse management tasks such as hardware provisioning, software patching, setup, configuration, monitoring nodes and drives to recover from failures, or backups.
Additionally Redshift also has automatic tuning capabilities which helps in efficient storage and query processing.

Q: What is Redshift Cluster?
Cluster is the core infrastructure component of an Amazon Redshift data warehouse.
It’s composed of one or more compute nodes and a leader node. Your client application interacts directly only with the leader node. which distributes and coordinate the query processing across multiple compute nodes.

Q: What is a Leader node?
The leader node manages communications with client programs and all communication with compute nodes. It parses and develops execution plans to carry out database operations, in particular, the series of steps necessary to obtain results for complex queries. Based on the execution plan, the leader node compiles code, distributes the compiled code to the compute nodes, and assigns a portion of the data to each compute node.
The leader node distributes SQL statements to the compute nodes only when a query references tables that are stored on the compute nodes. All other queries run exclusively on the leader node.

Q: What is a Compute node?
The leader node compiles code for individual elements of the execution plan and assigns the code to individual compute nodes. The compute nodes execute the compiled code and send intermediate results back to the leader node for final aggregation.
Each compute node has its own dedicated CPU, memory, and attached disk storage, which are determined by the node type. As your workload grows, you can increase the compute capacity and storage capacity of a cluster by increasing the number of nodes, upgrading the node type, or both.
Amazon Redshift provides several node types (DC2, RA3) for your compute and storage needs.

Q: What is a Node Slice?
A compute node is partitioned into slices. Each slice is allocated a portion of the node's memory and disk space, where it processes a portion of the workload assigned to the node. The leader node manages distributing data to the slices and apportions the workload for any queries or other database operations to the slices. The slices then work in parallel to complete the operation.
The number of slices per node is determined by the node size of the cluster. When you create a table, you can optionally specify one column as the distribution key. When the table is loaded with data, the rows are distributed to the node slices according to the distribution key that is defined for a table.

Q: How do I create redshift cluster?
You can easily create an Redshift cluster by using the AWS Management Console or the Amazon Redshift APIs.
You can start with a single node, which is best suited for evaluation or development/test workloads. It lets you get started with Amazon Redshift quickly.
The multi-node configuration requires a leader node that manages client connections and receives queries, and at least two compute nodes that store data and perform queries and computations. The leader node, which is the same size as the compute node, is provisioned for you automatically and you are not charged for it.
Simply specify your preferred Availability Zone (optional), the number of nodes, node types, a primary name and password, security groups, your preferences for backup retention, and other system settings.
Once you've chosen your desired configuration, Amazon Redshift will provision the required resources and set up your data warehouse cluster.

Q: How can I connect to the Amazon Redshift Cluster?
Once the data warehouse cluster is available, you can retrieve its endpoint and JDBC and ODBC connection string from the AWS Management Console or by using the Redshift APIs.
You can then use this connection string with your favorite database tool, programming language, or Business Intelligence (BI) tool.
You will need to authorize network requests to your running data warehouse cluster though.

Q: What is Redshift Console?
Redshift console provides the web-based interface to interact with Redshift cluster for cluster management, security, monitoring, configuration, query insights, marketplace and many other redshift aspects.
It also includes query editor so that you can run the redshift queries without installing any separate sql client at your end.

Q: What is Redshift Query Editor?
Amazon Redshift Query Editor is a web-based SQL client application that can be used to run queries on Redshift data warehouse. You can visualize query results with charts and collaborate by sharing queries with members of your team.
Additionally it provides several capabilities, such as the ability to browse and explore multiple databases, external tables, views, stored procedures, and user-defined functions. It provides wizards to create schemas, tables, and user-defined functions. It simplifies the management and collaboration of saved queries. You can also gain faster insights by visualizing the results with a single click.

Interview Questions - 2
Q: What are the different Instance Types in Redshift ?
Redshift provides following instance types to choose while creating or resizing the cluster.
RA3 - Flexible storage based on local SSDs and AWS S3
DC2 - uses local SSDs only
DS2 - uses local HDDs only
These instance types are further available in different sizes in terms of CPUs, Memory, Storage Capacity and Node Range.

Q: Is Redshift based on Relational Database (RDBMS) ?
Yes Amazon Redshift is a relational database management system (RDBMS). Although it provides the same functionality as a typical RDBMS, including online transaction processing (OLTP) functions such as inserting and deleting data, Amazon Redshift is optimized for high-performance analysis and reporting of very large datasets.

Q: What is the database engine Redshift uses?
Amazon Redshift is based on PostgreSQL which is one of the most popular open source relational database management system.

Q: What is the role of “Columnar Storage” in Redshift?
In a typical relational database table, each row contains field values for a single record. In row-wise database storage, data blocks store values sequentially for each consecutive column making up the entire row. In online transaction processing (OLTP) applications, most transactions involve frequently reading and writing all of the values for entire records, typically one record or a small number of records at a time. As a result, row-wise storage is optimal for OLTP databases.
Columnar storage works differently. In this mode, data is stored column wise, which means each data block stores values of a single column for multiple rows. This reduces the amount of data we need to load from disk, specially for the analytic queries. An added advantage is that, since each block holds the same type of data, block data can use a compression scheme selected specifically for the column data type, further reducing disk space and I/O.
Redshift uses the columnar storage to optimize data storage and query performance. As records enter the redshift ecosystem, it transparently converts the data to columnar storage for each of the columns.

Q: What does the Distribution Style mean in Redshift?
When you load the data into Redshift, it distributes the data rows to the compute nodes and its slices. The distribution of data depends on the distribution style we choose while creating the table.
When you execute a query, the query optimizer redistributes the rows to the compute nodes as needed to perform any joins and aggregations.The data distribution has two goals
distribute the workload uniformly among the nodes in the cluster
To minimize data movement as a query run
If either of this is skewed, our query performance can go wrong.
By choosing the best distribution style including the key, we can balance the data distribution and significantly improve overall system performance.

Q: What is a Sort Key?
Amazon Redshift stores your data on disk in sorted order according to the sort key. The query optimizer uses sort order when it determines optimal query plans.
Sort key(s) are used to scan the data efficiently and applicable for the queries which involve the range restricted predicates.

Q What are the different types of Sort Key?
Sort Key comes in two forms- interleaved and compound , compound being the default.
Compound is the default type. This can speed up the joins, group by, order by queries and also the compression of data. This is useful, specially where the predicates come with the prefix. But the query performance can be degraded if the primary column is not used as a predicate.
On the other hand interleaved key give equal weight to each column. They are good for the queries using different column at different point of time. An interleaved sort is more effective with large tables which require multiple 1 MB blocks per slice.

Q: What is the Workload Management?
Amazon Redshift workload management (WLM) enables users to flexibly manage priorities among various queries running in parallel based on the queues.
We can add multiple queues based on classifications. For instance we can have a separate queue for analytic workloads and a separate queue for ETL process. These queues have either a user group or the query group mapped to it.
When you run a query, WLM assigns the query to a queue according to the user's user group or by matching a query group that the user sets at runtime.
Currently, redshift uses automatic WLM by default, which manages query concurrency and memory allocation automatically.
With manual WLM, You can define up to eight queues. You can define the concurrency and the memory allocation for each of these queues.

Q: What is Short Query Acceleration?
Short query acceleration (SQA) prioritizes selected short-running queries ahead of longer-running queries. SQA runs short-running queries in a dedicated space, so that SQA queries aren't forced to wait in queues behind longer queries. SQA only prioritizes queries that are short-running and are in a user-defined queue.
Redshift uses machine learning capabilities to identify short running queries.

Q: What are the Materialized Views?
With the materialized view, a precomputed result set can be saved and served for the queries. This increases the performance significantly for the analytic queries which are repetitive and predictable in nature.
You can query the materialized views the same way as you would do with the tables.

Q: When to use RA3 instance type?
You can consider choosing RA3 node types in these cases:
You need the flexibility to scale and pay for compute separate from storage.
You query a fraction of your total data.
Your data volume is growing rapidly or is expected to grow rapidly.
You want the flexibility to size the cluster based only on your performance needs.
With RA3 instances with managed storage, you can choose the number of nodes based on your performance requirements, and pay only for the managed storage that you use. Built on the AWS Nitro System, RA3 instances with managed storage use high performance SSDs for your hot data and Amazon S3 for your cold data, providing ease of use, cost-effective storage, and fast query performance.

Q: What is “Managed Storage”?
Amazon Redshift managed storage is available with RA3 node types (with Serverless too) which helps in scaling the storage independent of the compute. This lets you size your cluster based on your compute needs only. This reduces the overall cost.
It automatically uses high-performance SSD-based local storage as tier-1 cache and takes advantage of optimizations such as data block temperature, data block age, and workload patterns to deliver high performance while scaling storage automatically to Amazon S3 when needed without requiring any action.

Q: What is Advanced Query Accelerator (AQUA)?
Advanced Query Accelerator (AQUA) is a new distributed and hardware-accelerated cache that automatically boost the query performance multifold.
It accelerates analytics queries by running data-intensive tasks such as scans, filtering, and aggregation closer to the storage layer. Most noticeable performance improvement can be seen on queries that require large scans, especially those with LIKE and SIMILAR_TO predicates.
AQUA is available with the RA3 instance type at no additional charge. You do not need additional code changes to enable it.
